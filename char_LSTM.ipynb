{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_LSTM.ipynb",
      "provenance": [],
      "mount_file_id": "1nG-IMKtvnFGk2vUh7uGj5i4lblLKzBTw",
      "authorship_tag": "ABX9TyMzG7PE4eaZhMid0gBRzB4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttury/Deep-Learning-For-Natural-Language-Processing/blob/master/char_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9s_054aIs6x"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "  line = line.strip() # \\r, \\n 제거\n",
        "  line = line.lower()\n",
        "  line = line.decode('ascii', 'ignore') # 아스키 문자만 남기고 삭제\n",
        "  if len(line) > 0:\n",
        "    lines.append(line)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZWWGVsVKIP8",
        "outputId": "eba0ee52-9e60-48dd-bb87-305d215e50d8"
      },
      "source": [
        "print(lines[:5])\n",
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 개수 : %d' % len(text))\n",
        "print(text[:200])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll', 'this ebook is for the use of anyone anywhere in the united states and', 'most other parts of the world at no cost and with almost no restrictions', 'whatsoever. you may copy it, give it away or re-use it under the terms', 'of the project gutenberg license included with this ebook or online at']\n",
            "문자열의 길이 또는 총 글자의 개수 : 159484\n",
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Fe7RHJjOPP",
        "outputId": "0893ae2a-3080-463e-aff9-900cce221d77"
      },
      "source": [
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('글자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvlEAuw6juqn",
        "outputId": "8b895d70-55df-48da-a2f0-78b86420e4f6"
      },
      "source": [
        "char_to_index = dict((c, i) for (i, c) in enumerate(char_vocab))\n",
        "print(char_to_index)\n",
        "\n",
        "index_to_char = dict((i, c) for (c, i) in char_to_index.items())\n",
        "print(index_to_char)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n",
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsADBVK0lZ7g",
        "outputId": "284e8724-7500-4a3e-eb4d-9c98db95d74f"
      },
      "source": [
        "seq_length = 60 # 문장의 길이를 60으로 설정\n",
        "n_samples = int(np.floor((len(text) - 1) / seq_length)) # y_train을 오른쪽으로 한번 shift 해야 하므로 1을 빼줌\n",
        "print('문장 샘플의 수 {}'.format(n_samples))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R01boVcUmCKE",
        "outputId": "2eac272a-9d09-4e56-b7fe-2022bc144f32"
      },
      "source": [
        "x_train = list()\n",
        "y_train = list()\n",
        "\n",
        "for i in range(n_samples):\n",
        "  x_sample  = text[i * seq_length : (i + 1) * seq_length]\n",
        "  x_encoded = [char_to_index[ch] for ch in x_sample]\n",
        "  x_train.append(x_encoded)\n",
        "\n",
        "  y_sample = text[i * seq_length + 1 : (i + 1) * seq_length + 1]\n",
        "  y_encoded = [char_to_index[ch] for ch in y_sample]\n",
        "  y_train.append(y_encoded)\n",
        "\n",
        "print(x_train[0])\n",
        "print(y_train[0])\n",
        "print(x_train[1])\n",
        "print(y_train[1])\n",
        "print(np.array(x_train).shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n",
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n",
            "(2658, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE5VIZF7qZvj",
        "outputId": "73c64a09-541a-40d4-f2bd-97d1a1e0032f"
      },
      "source": [
        "# 글자 단위 RNN에서는 입력 시퀀스에 대해 워드 임베딩을 하지 않으므로 입력 시퀀스인 x_train에 대해서도 원-핫 인코딩 수행\n",
        "\n",
        "x_train = to_categorical(x_train) # one-hot encoding\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "print('x_train의 크기(shape) : {}'.format(x_train.shape))\n",
        "print('y_train의 크기(shape) : {}'.format(y_train.shape))\n",
        "# batch_size(num_of_samples) = 2658, timesteps(input_length) = 60, input_dim(vocab_size) = 56)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train의 크기(shape) : (2658, 60, 56)\n",
            "y_train의 크기(shape) : (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UYY1XG23Az3",
        "outputId": "b9f2a4e7-cf55-48e3-cca0-17e33968c28e"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
        "\n",
        "model = Sequential()\n",
        "# input_sequence : (2658, 60, 56)\n",
        "model.add(LSTM(256, input_shape=(None, x_train.shape[2]), return_sequences=True))\n",
        "# (2658, 60, 56) --LSTM-> (2658, 60, 256)\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "# (2658, 60, 256) --LSTM-> (2658, 60, 256)\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
        "# (2658, 60, 256) --softmax-> (2658, 60, 56)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=80, verbose=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84/84 - 41s - loss: 0.7682 - accuracy: 0.7718\n",
            "Epoch 70/80\n",
            "84/84 - 41s - loss: 0.7500 - accuracy: 0.7773\n",
            "Epoch 71/80\n",
            "84/84 - 40s - loss: 0.7246 - accuracy: 0.7858\n",
            "Epoch 72/80\n",
            "84/84 - 41s - loss: 0.7102 - accuracy: 0.7904\n",
            "Epoch 73/80\n",
            "84/84 - 41s - loss: 0.6933 - accuracy: 0.7959\n",
            "Epoch 74/80\n",
            "84/84 - 41s - loss: 0.6737 - accuracy: 0.8024\n",
            "Epoch 75/80\n",
            "84/84 - 41s - loss: 0.6625 - accuracy: 0.8048\n",
            "Epoch 76/80\n",
            "84/84 - 41s - loss: 0.6646 - accuracy: 0.8011\n",
            "Epoch 77/80\n",
            "84/84 - 42s - loss: 0.6248 - accuracy: 0.8180\n",
            "Epoch 78/80\n",
            "84/84 - 42s - loss: 0.6087 - accuracy: 0.8235\n",
            "Epoch 79/80\n",
            "84/84 - 42s - loss: 0.6093 - accuracy: 0.8204\n",
            "Epoch 80/80\n",
            "84/84 - 41s - loss: 0.5815 - accuracy: 0.8311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa34516ef10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYHCtQJJ-bV"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]] # 랜덤 인덱스로부터 글자 생성\n",
        "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
        "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTegvl2ARvkG"
      },
      "source": [
        "rm -r drive"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "teteojRyD2m4",
        "outputId": "a71a8d28-0696-4926-f079-fb65a79cc0f0"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30 번 글자 a 로 예측을 시작!\n",
            "and now alice to herself in a tone of great collectee to herself, and the mock turtle in the directi"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'and now alice to herself in a tone of great collectee to herself, and the mock turtle in the directio'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCtzwIdlISps",
        "outputId": "d68bbba5-47dc-4034-bc1c-6dfaf5862c74"
      },
      "source": [
        "model.save('./drive/MyDrive/models/LSTM_by_char')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/LSTM_by_char/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./drive/MyDrive/models/LSTM_by_char/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}