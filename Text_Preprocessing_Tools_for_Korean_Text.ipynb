{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Preprocessing_Tools_for_Korean_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiXLwOepJw/hNvS1d1jW5c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttury/Deep-Learning-For-Natural-Language-Processing/blob/master/Text_Preprocessing_Tools_for_Korean_Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cxlgOrVyebk"
      },
      "source": [
        "# **한국어 전처리 패키지**\n",
        "---\n",
        "\n",
        "<br/>\n",
        "\n",
        "## PyKoSpacing(띄어쓰기)\n",
        "---\n",
        "> 딥러닝 기반 한국어 띄어쓰기 모델\n",
        "\n",
        "<br/>\n",
        "\n",
        "## Py-Hanspell(맞춤법)\n",
        "---\n",
        "> 네이버 한글 맞춤법 검사기 모델\n",
        "\n",
        "> PyKoSpacing과 같이 띄어쓰기도 지원\n",
        "\n",
        "<br/>\n",
        "\n",
        "## **SOYNLP를 이용한 단어 토큰화**\n",
        "---\n",
        "> 기존 형태소 분석기와 달리 신조어도 구분할 수 있다\n",
        "\n",
        "> 비지도학습 기반의 단어 토크나이저이므로 사용 전 코퍼스 학습이 필요하다\n",
        "\n",
        "> **응집 확률** : 함께 응집하여 나타나는 빈도가 높은 문자열일수록 단어일 확률이 높다\n",
        "\n",
        "> **브랜칭 엔트로피** : 다음에 올 문자를 예측 가능한 정도가 단어를 판단의 지표가 된다\n",
        "\n",
        "<br/>\n",
        "\n",
        "## SOYNLP -> L tokenizer\n",
        "---\n",
        "> 한국어 띄어쓰기 단위로 나눈 어절 토큰은 주로 L 토큰 + R 토큰의 형식을 가진다\n",
        "\n",
        "> 분리 기준으로 L 토큰을 찾아내는 원리\n",
        "\n",
        "<br/>\n",
        "\n",
        "## SOYNLP -> Max Score tokenizer\n",
        "---\n",
        "> 띄어쓰기가 되어 있지 않은 문장에서 점수가 높은 문자열을 단어로 구분해 토큰화한다\n",
        "\n",
        "<br/>\n",
        "\n",
        "## SOYNLP -> Normalizer\n",
        "---\n",
        "> ㅋㅋ, ㅎㅎ 등의 반복되는 이모티콘 또는 의미 없게 반복되는 문자열을 정규화\n",
        "\n",
        "<br/>\n",
        "\n",
        "## Customized KoNLPy\n",
        "---\n",
        "> 형태소 분석기에 없는 단어를 구분하기 위해 사용자 사전을 쉽게 추가할 수 있음\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piQQB3R21cT3"
      },
      "source": [
        "\n",
        "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCZQBQq92Gkd"
      },
      "source": [
        "# PyKoSpacing(한국어 띄어쓰기 패키지)\n",
        "\n",
        "from pykospacing import spacing\n",
        "\n",
        "text = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
        "new_text = text.replace(' ', '')\n",
        "print(new_text)\n",
        "print()\n",
        "\n",
        "kospacing_text = spacing(new_text)\n",
        "print(text)\n",
        "print()\n",
        "print(kospacing_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGGHMklK2vwm"
      },
      "source": [
        "pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQod2HrS276F"
      },
      "source": [
        "# Py-Hanspell(네이버 맞춤법 검사기)\n",
        "\n",
        "from hanspell import spell_checker\n",
        "\n",
        "sent = \"맞춤법 틀리면 외 않되? 쓰고싶은대로쓰면돼지\"\n",
        "spelled_sent = spell_checker.check(sent)\n",
        "hanspell_sent = spelled_sent.checked\n",
        "\n",
        "print(hanspell_sent)\n",
        "print()\n",
        "\n",
        "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
        "new_sent = sent.replace(' ', '')\n",
        "spelled_sent = spell_checker.check(new_sent)\n",
        "hanspell_sent = spelled_sent.checked\n",
        "\n",
        "print(hanspell_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPLTLBzAT0TX"
      },
      "source": [
        "pip install soynlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSzUuVPTrFu"
      },
      "source": [
        "# SOYNLP를 이용한 단어 토큰화\n",
        "\n",
        "import urllib.request\n",
        "from soynlp import DoublespaceLineCorpus\n",
        "from soynlp.word import WordExtractor\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")\n",
        "\n",
        "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
        "print(len(corpus))\n",
        "print()\n",
        "\n",
        "i = 0\n",
        "for document in corpus:\n",
        "  if len(document) > 0:\n",
        "    print(document)\n",
        "    print()\n",
        "    i += 1\n",
        "  if i == 3:\n",
        "    break\n",
        "\n",
        "word_extractor = WordExtractor()\n",
        "word_extractor.train(corpus)\n",
        "word_score_table = word_extractor.extract()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BNcpdT6_0Lo"
      },
      "source": [
        "# SOYNLP의 응집 확률\n",
        "\n",
        "print(word_score_table[\"반포한\"].cohesion_forward)\n",
        "print(word_score_table[\"반포한강\"].cohesion_forward)\n",
        "print(word_score_table[\"반포한강공\"].cohesion_forward)\n",
        "print(word_score_table[\"반포한강공원\"].cohesion_forward)\n",
        "print(word_score_table[\"반포한강공원에\"].cohesion_forward)\n",
        "print()\n",
        "\n",
        "print(word_score_table[\"디스\"].right_branching_entropy) # 디스코드, 디스카운트 등 다양함\n",
        "print(word_score_table[\"디스플\"].right_branching_entropy) # 디스플레이가 명백\n",
        "print(word_score_table[\"디스플레\"].right_branching_entropy)\n",
        "print(word_score_table[\"디스플레이\"].right_branching_entropy) # 조사나 다른 단어가 뒤에 붙을 수 있어 엔트로피가 높음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6oZnGEQB3c2"
      },
      "source": [
        "# SOYNLP -> L tokenizer\n",
        "\n",
        "from soynlp.tokenizer import LTokenizer\n",
        "\n",
        "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
        "l_tokenizer = LTokenizer(scores = scores)\n",
        "l_tokenized = l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten = False)\n",
        "\n",
        "print(l_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwolErJztXRK"
      },
      "source": [
        "# SOYNLP -> Max Score tokenizer\n",
        "\n",
        "from soynlp.tokenizer import MaxScoreTokenizer\n",
        "\n",
        "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
        "maxscore_tokenizer = MaxScoreTokenizer(scores = scores)\n",
        "maxscore_tokenized = maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")\n",
        "\n",
        "print(maxscore_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7-yDMJjuA2h"
      },
      "source": [
        "# 반복되는 문자 정제\n",
        "\n",
        "from soynlp.normalizer import *\n",
        "\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
        "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
        "print()\n",
        "\n",
        "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
        "print(repeat_normalize('와하하하하핫', num_repeats=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6agmj_cw3kB"
      },
      "source": [
        "pip install customized_konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7JcnLGPxBIg"
      },
      "source": [
        "# 형태소 분석기에 사용자 사전 추가\n",
        "\n",
        "from ckonlpy.tag import Twitter\n",
        "\n",
        "twitter = Twitter()\n",
        "print(twitter.morphs('은경이는 사무실로 갔습니다.'))\n",
        "print()\n",
        "\n",
        "twitter.add_dictionary('은경이', 'Noun')\n",
        "print(twitter.morphs('은경이는 사무실로 갔습니다.'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}