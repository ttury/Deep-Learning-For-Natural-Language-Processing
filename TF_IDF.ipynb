{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzMhU2ZseAS6sYNNoC9uno",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttury/Deep-Learning-For-Natural-Language-Processing/blob/master/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c-1Cm8Fbi0V"
      },
      "source": [
        "# **TF-IDF**\n",
        "---\n",
        "> dtm 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
        "\n",
        "> TF-IDF = TF(Term Frequency * IDF(Inverse Document Frequency)\n",
        "\n",
        "<br/>\n",
        "\n",
        "* d : 특정 문서\n",
        "* t : 특정 단어\n",
        "* n : 문서 개수\n",
        "\n",
        "<br/>\n",
        "\n",
        "> tf(d, t)\n",
        "* 특정 문서 d에서의 특정 단어 t의 등장 횟수\n",
        "* DTM 값을 그대로 사용\n",
        "\n",
        "> df(t)\n",
        "* 특정 단어 t가 등장한 문서의 수\n",
        "\n",
        "> idf(d, t)\n",
        "* df와 반비례하는 수\n",
        "* $idf(d, t) = \\ln(\\frac{n}{1+df(t)})$\n",
        "* 분모가 0이 되지 않도록 df(t)에 1을 더함\n",
        "* 1 + d(f) = n일 때 idf가 0이 되지 않도록 계산 마지막에 1을 더하기도 함\n",
        "* TF-IDF 값들이 너무 큰 격차를 갖지 않도록 자연로그 사용\n",
        "\n",
        "<br/>\n",
        "\n",
        "## 사이킷런 이용\n",
        "---\n",
        "> DTM\n",
        "* CountVectorizer 사용\n",
        "\n",
        "> TF-IDF\n",
        "* TfidfVectorizer 사용\n",
        "* TF-IDF 값을 구할 때 약간 다른 식을 사용\n",
        "\n",
        "<br/>\n",
        "\n",
        "DTM : https://wikidocs.net/24559\n",
        "<br/>\n",
        "TF-IDF = https://wikidocs.net/31698\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCemxu3-bTIk"
      },
      "source": [
        "import pandas as pd\n",
        "from math import log\n",
        "\n",
        "docs = [\n",
        "        '먹고 싶은 사과',\n",
        "        '먹고 싶은 바나나',\n",
        "        '길고 노란 바나나 바나나',\n",
        "        '저는 과일이 좋아요'\n",
        "]\n",
        "# vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab = set()\n",
        "for doc in docs:\n",
        "  vocab.update(doc.split())\n",
        "vocab = list(vocab)\n",
        "vocab.sort()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UWr9LY1m1UJ"
      },
      "source": [
        "num_of_docs = len(docs)\n",
        "\n",
        "def term_frequency(term, doc):\n",
        "  return doc.count(term) # 문자열 count 함수 : 문자열 속 문자열 개수 찾기\n",
        "\n",
        "def doc_frequency(term):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += term in doc # 문서에 존재하면 1, 아니면 0\n",
        "  return df\n",
        "\n",
        "def inv_doc_frequency(term):\n",
        "  df = doc_frequency(term)\n",
        "  return log(num_of_docs / (df + 1))\n",
        "\n",
        "def tf_idf(term, doc):\n",
        "  return term_frequency(term, doc) * inv_doc_frequency(term)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5nL53yAniJA"
      },
      "source": [
        "result = list()\n",
        "for doc in docs:\n",
        "  result.append([]) # 2차원 리스트에서 하나의 행\n",
        "  for term in vocab: # 열이 단어 사전 기준\n",
        "    result[-1].append(term_frequency(term, doc)) # 작성 중인 행에 tf 값 넣기\n",
        "\n",
        "tf = pd.DataFrame(result, columns = vocab)\n",
        "print(tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp6PGTNEp9GK"
      },
      "source": [
        "result = list(map(inv_doc_frequency, vocab))\n",
        "\n",
        "idf = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
        "print(idf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_mLvOLsrrNH"
      },
      "source": [
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 10)\n",
        "\n",
        "result = list()\n",
        "for doc in docs:\n",
        "  result.append([])\n",
        "  for term in vocab:\n",
        "    result[-1].append(tf_idf(term, doc))\n",
        "\n",
        "tfidf = pd.DataFrame(result, columns = vocab)\n",
        "print(tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLpCx05_1SnQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "          'you know I want your love',\n",
        "          'I like you',\n",
        "          'what should I do'\n",
        "]\n",
        "count_vector = CountVectorizer()\n",
        "print(count_vector.fit_transform(corpus).toarray())\n",
        "print(count_vector.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_ZLDwDjujI1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "          'you know i want your love',\n",
        "          'I like you',\n",
        "          'what should i do'\n",
        "]\n",
        "tfidf_vector = TfidfVectorizer().fit(corpus)\n",
        "print(tfidf_vector.transform(corpus).toarray())\n",
        "print(tfidf_vector.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}